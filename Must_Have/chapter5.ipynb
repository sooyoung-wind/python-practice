{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "1. [분류와 회귀](#분류와-회귀)  \n",
    "    1.1. [분류](#분류)  \n",
    "    1.2. [회귀](#회귀)  \n",
    "2. [분류 평가지표](#분류-평가지표)  \n",
    "    2.1. [오차 행렬(confusion matrix)](#오차-행렬confusion-matrix)  \n",
    "    2.2. [로그 손실](#로그-손실)  \n",
    "    2.3. [ROC 곡선과 AUC](#ROC-곡선과-AUC)  \n",
    "3. [데이터 인코딩](#데이터-인코딩)  \n",
    "    3.1. [레이블 인코딩](#레이블-인코딩)  \n",
    "    3.2. [오디널 인코딩](#오디널-인코딩)  \n",
    "    3.3. [원핫 인코딩](#원핫-인코딩)  \n",
    "4. [피쳐 스케일링](#피쳐-스케일링)  \n",
    "    4.1. [min-max 정규화(normalization)](#min-max-정규화normalization)  \n",
    "    4.2. [표준화(standardization)](#표준화standardization)  \n",
    "5. [교차 검증](#교차-검증)  \n",
    "    5.1. [K 폴드 교차 검증](#K-폴드-교차-검증)  \n",
    "    5.2. [층화 K 폴드 교차 검증](#층화-K-폴드-교차-검증)  \n",
    "6. [주요 머신러닝 모델](#주요-머신러닝-모델)  \n",
    "    6.1. [선형 회귀 모델](#선형-회귀-모델)  \n",
    "    6.2. [로지스틱 회귀 모델](#로지스틱-회귀-모델)  \n",
    "    6.3. [결정 트리](#결정-트리)  \n",
    "    6.4. [앙상블 학습](#앙상블-학습)  \n",
    "    6.5. [랜덤 포레스트](#랜덤-포레스트)  \n",
    "    6.6. [XGBoost](#XGBoost)  \n",
    "    6.7. [LightGBM](#LightGBM)  \n",
    "7. [하이퍼 파라미터 최적화](#하이퍼-파라미터-최적화)  \n",
    "    7.1. [그리드서치](#그리드서치)  \n",
    "    7.2. [랜덤서치](#랜덤서치)  \n",
    "    7.3. [베이지안 최적화](#베이지안-최적화) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"분류와-회귀\"></a>\n",
    "# 분류와 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "캐글 경진대회는 대부분 분류나 회귀 문제를 다룬다. 타깃값이 범주형 데이터면 분류문제, 수치형이면 회귀 문제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"분류\"></a>\n",
    "## 분류\n",
    "책의 내용을 피처, IT 도서을 타깃을 비유함. 책을 분류하는 방법에 대한 설명\n",
    "\n",
    "### 5.1.1 분류\n",
    "이진 분류(binary clasification) : 타깃값이 2개인 분류\n",
    "다중 분류(multicalss classification) : 타깃값이 3개 이상인 분류\n",
    "\n",
    "### 5.1.2 회귀\n",
    "독립변수(independent variable) : 영향을 미치는 변수\n",
    "종속변수(dependent variable) : 영향을 받는 변수\n",
    "회귀란 독립변수와 종속변수 간 관계를 모델링하는 방법이다.\n",
    "\n",
    "선형회귀(simple linear regression) : y = ax + b\n",
    "다중 선형회귀(multiple linear regression) : y = ax + by + c\n",
    "\n",
    "### 자주 사용하는 회귀 평가지표\n",
    "- MAE : 평균절대오차\n",
    "- MSE : 평균제곱오차\n",
    "- RMSE : 평균제곱근 오차\n",
    "- MSLE : Mean Squared Log Error\n",
    "- RMSLE : Root Mean Squared Log Error\n",
    "- R^2 : 결정계수\n",
    "\n",
    "RMSE vs. RMSLE\n",
    "1. 아웃라이어에 강건하다. : 이상치 또는 아웃라이어가 있더라도 값의 변동폭이 크지 않다.\n",
    "2. 상대적 Error 측정 : 상대적 및 절대적 차이에 의해 RMSE는 변화하지만, RMSLE은 예측값과 실제값의 상대적 error를 측정한다.\n",
    " - 단, RMSLE의 한계는 예시로 돈 관련 문제에 적용할 때 1억과 100억의 오차와 1원과 100원의 오차 의미가 퇴색하게 된다.\n",
    "3. Under Estimation에 큰 패널티를 부여한다.\n",
    " - RMSLE는 over estimation보다 under estimation에 더 큰 패널티를 부여한다. 즉, 예측값이 실제보다 작을 때 더 큰 패널티를 부여한다.  \n",
    " - 예를 배달에서 30분이 걸린다고 했는데 20분이 걸리는건 문제가 없지만, 20분이 걸린다고 했는데 30분이 걸린다면 문제가 있다고 볼 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|평가지표|수식|설명|\n",
    "|--|--|--|\n",
    "|MAE|$${1 \\over N} \\sum_{i=1}^N\\|y_i - \\hat{y_i}\\|$$||\n",
    "|MSE|$${1 \\over N} \\sum_{i=1}^N(y_i - \\hat{y_i})^2$$||\n",
    "|RMSE|$$\\sqrt{{1 \\over N} \\sum_{i=1}^N(y_i - \\hat{y_i})^2}$$||\n",
    "|MSLE|$${1 \\over N} \\sum_{i=1}^N(log(y_i+1)-log(\\hat{y_i}+1))^2$$|$$-\\infty$$를 방지하기 위하여 log에 +1을 취함|\n",
    "|RMSLE|$$\\sqrt{{1 \\over N} \\sum_{i=1}^N(log(y_i+1)-log(\\hat{y_i}+1))^2}$$|$$-\\infty$$를 방지하기 위하여 log에 +1을 취함|\n",
    "|$$R^2$$|$$ \\hat{\\sigma}^2 \\over {\\sigma}^2$$|1에 근첩하는게 정확도가 높음|  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"회귀\"></a>\n",
    "## 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t 0.8182\n",
      "MSE:\t 4.0909\n",
      "RMSE:\t 2.0226\n",
      "MSLE:\t 0.1298\n",
      "RMSLE:\t 0.3603\n",
      "R2:\t -0.0185\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "true = np.array([1,2,3,4,5,7,8,6,4,4,3])\n",
    "pred = np.array([1,2,3,4,5,7,2,6,4,7,3])\n",
    "\n",
    "MAE = mean_absolute_error(true, pred)\n",
    "MSE = mean_squared_error(true, pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MSLE = mean_squared_log_error(true, pred)\n",
    "RMSLE = np.sqrt(MSLE)\n",
    "R2 = r2_score(true, pred)\n",
    "\n",
    "print(f'MAE:\\t {MAE:.4f}')\n",
    "print(f'MSE:\\t {MSE:.4f}')\n",
    "print(f'RMSE:\\t {RMSE:.4f}')\n",
    "print(f'MSLE:\\t {MSLE:.4f}')\n",
    "print(f'RMSLE:\\t {RMSLE:.4f}')\n",
    "print(f'R2:\\t {R2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"분류-평가지표\"></a>\n",
    "# 분류 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"오차-행렬confusion-matrix\"></a>\n",
    "## 오차 행렬(confusion matrix)\n",
    "\n",
    "<table>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td>predict</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td>positive</td>\n",
    "      <td>negative</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td rowspan=\"2\">real</td>\n",
    "      <td>positive</td>\n",
    "      <td>TP</td>\n",
    "      <td>FN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>negative</td>\n",
    "      <td>FP</td>\n",
    "      <td>TN</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "참 양성(True Positive, TP) : 양성으로 정답을 맞춘 경우  \n",
    "참 음성(True Negative, TN) : 음성으로 정답을 맞춘 경우  \n",
    "거짓 양성(False Positive, FP) : 양성으로 못 맞춘 경우  \n",
    "거짓 음성(False Negative, TN) : 음성으로 못 맞춘 경우  \n",
    "\n",
    "오차 행렬을 활용한 지표는 정확도, 정밀도, 재현율, F1 점수가 있다.  \n",
    "\n",
    "* 정확도(accuracy) : 정확도는 잘 쓰이지 않는다.  \n",
    "전체에서 True가 차지하는 비율  \n",
    "(*모델의 우수성을 따질때 잘 사용하지 않음)  \n",
    "$${TP+TN}\\over{TP+TN+FP+FN}$$\n",
    "\n",
    "* 정밀도(precision) : 정밀도는 음성을 양성으로 잘못 판단하면 문제가 발생하는 경우에 사용한다. 검출하기 원하는 상태를 보통 양성으로 정한다. 즉, 문제가 되는 상태를 양성, 정상인 상태를 음성이라고 본다.  \n",
    "Positive predict중의 True가 차지하는 비율  \n",
    "(*실제 negative가 positive로 측정되는것이 critical할때 사용)  \n",
    "$${TP}\\over{TP+FP}$$\n",
    "\n",
    "* 재현율(recall)(TPR) : 양성을 음성으로 잘못 판단하면 준제가 되는 경우에 사용한다.(예, 암진단)\n",
    "positive real중의 True가 차지하는 비율  \n",
    "(*실제 positive가 negative로 측정되는것이 critical할때 사용)  \n",
    "$${TP}\\over{TP+FN}$$\n",
    "\n",
    "* F1 점수(F1 score)  \n",
    "정밀도와 재현율의 조화평균으로 편중되지않은 균등한 모델을 만들때 사용  \n",
    "$${2}\\over{{{1} \\over {precision}}+{{1} \\over {recall}}}$$\n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"로그-손실\"></a>\n",
    "## 로그 손실\n",
    "\n",
    "타겟을 확률적으로 예측시 사용되는 모델(0에 가까울 수록 좋음)  \n",
    "$$logloss = -{{1}\\over{N}}\\sum_{i=1}^N(y_ilog(\\hat{y_i})+(1-y_i)log(1-\\hat{y_i}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ROC-곡선과-AUC\"></a>\n",
    "## ROC 곡선과 AUC\n",
    "- ROC(Receiver Operating Characteristic)곡선은 참 양성 비율(TPR)에 대한 거짓 양성 비율(FPR)곡선이다.  \n",
    "- AUC(Area Under the Curve)는 ROC 곡선 아래 면적을 의미한다.  \n",
    "\n",
    "로그손실과 같이 예측값이 확률일때 사용하게 된다.  \n",
    "$$TNR = {{TN}\\over{FP+TN}}$$\n",
    "$$FPR = 1 - TNR$$  \n",
    "\n",
    "TNR은 특이도(specificity)라고도 불린다.\n",
    "<center>\n",
    "  <img\n",
    "    src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Roc_curve.svg/512px-Roc_curve.svg.png\"\n",
    "    width=\"350\"\n",
    "    height=\"400\"\n",
    "  />\n",
    "</center>\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"데이터-인코딩\"></a>\n",
    "# 데이터 인코딩\n",
    "\n",
    "대표적인 데이터 인코딩에서는 **레이블 인코딩**과 **원-핫 인코딩**이 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"레이블-인코딩\"></a>\n",
    "## 레이블 인코딩  \n",
    "\n",
    "레이블 인코딩을 적용하면 원본 데이터의 값에 사전순으로 번호를 매깁니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 인코딩 적용 후 데이터: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "fruits = ['banana', 'berry', 'blueberry']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "fruits_label_encoded = label_encoder.fit_transform(fruits)\n",
    "\n",
    "print('레이블 인코딩 적용 후 데이터:', fruits_label_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"오디널-인코딩\"></a>\n",
    "## 오디널 인코딩  \n",
    "범주형 데이터를 숫자로 1대1 매칭해주는 방법(고차원 데이터)  \n",
    "데이터간의 상관관계가 있을 때 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"원핫-인코딩\"></a>\n",
    "## 원핫 인코딩  \n",
    "범주형 데이터 value수 만큼 feature를 늘려서 해당하면 1 아니면 0을 나타냄  \n",
    "메모리를 아끼기 위해서 Compressed spares row로 변환됨  \n",
    "데이터간의 상관관계가 없을 때 사용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 적용 후 데이터: \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "fruits = ['banana', 'berry', 'blueberry']\n",
    "\n",
    "# 레이블 인코더, 원-핫 인코더 생성\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "# 레이블 인코딩 적용(문자 데이터 -> 숫자 데이터)\n",
    "fruits_onehot_encoded = label_encoder.fit_transform(fruits)\n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "# reshape의 -1 값은 다른 인자 값에 따라 의존적으로 변화는 값을 의미한다.  \n",
    "fruits_onehot_encoded = onehot_encoder.fit_transform(fruits_label_encoded.reshape(-1,1))\n",
    "\n",
    "print('원-핫 인코딩 적용 후 데이터: \\n', fruits_onehot_encoded.toarray())\n",
    "\n",
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>banana</th>\n",
       "      <th>berry</th>\n",
       "      <th>blueberry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   banana  berry  blueberry\n",
       "0    True  False      False\n",
       "1   False   True      False\n",
       "2   False  False       True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.get_dummies(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"피쳐-스케일링\"></a>\n",
    "# 피쳐 스케일링  \n",
    "\n",
    "피쳐들마다 범위가 다르기때문에 범위를 조절하는 기법  \n",
    "단, 트리 기반 모델(랜덤 포레시트, XGBoost, LightGBM 등)은 피처 스케일링이 필요 없다.  \n",
    "트리 기반 모델은 데이터의 크기보다는 대소 관계에 영향을 받기 때문이다. 피처 스케일링을 하더라도 데이터의 대소 관계에는 변함이 없다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"min-max-정규화normalization\"></a>\n",
    "## min-max 정규화(normalization)  \n",
    "\n",
    "0~1의 범위의 값으로 수치를 변화시키는것을 의미하며 아래의 식으로 변환됨  \n",
    "(outlier에 취약함)  \n",
    "$$x_{scaled} = {{x-x_{min}} \\over {x_{max}-x_{min}}}$$\n",
    "fit, transform을 따로 할때 음수 발현가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      키  몸무게\n",
      "광일  1.7   75\n",
      "혜성  1.5   55\n",
      "덕수  1.8   60\n",
      "[[0.66666667 1.        ]\n",
      " [0.         0.        ]\n",
      " [1.         0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "height_weight_dict = {'키': [1.7, 1.5, 1.8], '몸무게': [75, 55, 60]}\n",
    "df = pd.DataFrame(height_weight_dict, index=['광일', '혜성', '덕수'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df) # df 데이터에서 min max를 사용하여 동작\n",
    "df_scaled = scaler.transform(df) # 여기서는 예시로 df를 했지만 다른 데이터를 입력하면 앞에서 사용한 min max를 적용하는 부분\n",
    "# 예시\n",
    "# df_scaled2 = scaler.transform(df2)\n",
    "# df_scaled3 = scaler.transform(df3)\n",
    "\n",
    "print(df)\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"표준화standardization\"></a>\n",
    "## 표준화(standardization)  \n",
    "\n",
    "평균이 0, 분산이 1이 되게 피쳐를 조정(정규분포를 따르는 데이터는 표준화 스케일링을 적용하는게 좋다.)\n",
    "$$x_{scaled} = {{x-\\hat{x}}\\over{\\sigma}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      키  몸무게\n",
      "광일  1.7   75\n",
      "혜성  1.5   55\n",
      "덕수  1.8   60\n",
      "[[ 0.26726124  1.37281295]\n",
      " [-1.33630621 -0.98058068]\n",
      " [ 1.06904497 -0.39223227]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "height_weight_dict = {'키': [1.7, 1.5, 1.8], '몸무게': [75, 55, 60]}\n",
    "df = pd.DataFrame(height_weight_dict, index=['광일', '혜성', '덕수'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "df_scaled = scaler.transform(df)\n",
    "\n",
    "print(df)\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"교차-검증\"></a>\n",
    "# 교차 검증  \n",
    "\n",
    "성능검증의 필요성  \n",
    "1. 과적합 : 모델 과적합을 피할 수 있다.\n",
    "2. 캐글에서 제출하기 전까지 성능을 확인하기 어렵다.\n",
    "\n",
    "위의 2가지를 위해서 교차 검증을 사용한다. 가장 일반적인 방법이 K 폴드 교차 검증이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"K-폴드-교차-검증\"></a>\n",
    "## K 폴드 교차 검증  \n",
    "1. 전체 훈련 데이터를 K개 그룹으로 나눈다.  \n",
    "2. 그룹 하는 검증 데이터로, 나머지 K-1개는 훈련 데이터로 지정한다.  \n",
    "3. 훈련 데이터로 모델을 훈련하고, 검증 데이터로 평가한다.  \n",
    "4. 평가점수를 기록한다.  \n",
    "5. 검증 데이터를 다른 그룹으로 바꿔가며 2~4 절차를 K번 반복한다.  \n",
    "6. K개 검증 평가점수의 평균을 구한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 4 5 6 7 8] [3 9]\n",
      "[0 1 2 3 4 5 6 9] [7 8]\n",
      "[0 1 3 4 6 7 8 9] [2 5]\n",
      "[0 2 3 5 6 7 8 9] [1 4]\n",
      "[1 2 3 4 5 7 8 9] [0 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train, valid in folds.split(data):\n",
    "    print(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"층화-K-폴드-교차-검증\"></a>\n",
    "## 층화 K 폴드 교차 검증  \n",
    "층화 K 폴드 교차 검증은 타깃값이 폴드마다 골고루 분포되게 나누는 방법이다. \n",
    "> 주위! 층화 K 폴드 교차 검증은 **분류 분제**에서만 쓰인다.\n",
    "> (저자 주) 근듕한 비율로 나누기 위해서는 타깃값이 유한해야 하다고 한다. 즉, 연속된 값이면 동일한 비율이 안된다는 뜻임.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flod 1 검증 데이터 타깃값:\n",
      "['일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 2 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 3 검증 데이터 타깃값:\n",
      "['스팸' '스팸' '스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 4 검증 데이터 타깃값:\n",
      "['일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 5 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "y = np.array(['스팸']*5 + ['일반']*45)\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(y)):\n",
    "    print(f'Flod {idx+1} 검증 데이터 타깃값:')\n",
    "    print(y[valid_idx], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flod 1 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 2 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 3 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 4 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n",
      "Flod 5 검증 데이터 타깃값:\n",
      "['스팸' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반' '일반'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array(range(0,100,2))\n",
    "y = np.array(['스팸']*5 + ['일반']*45)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X,y)):\n",
    "    print(f'Flod {idx+1} 검증 데이터 타깃값:')\n",
    "    print(y[valid_idx], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"주요-머신러닝-모델\"></a>\n",
    "# 주요 머신러닝 모델\n",
    "\n",
    "+ 선형회귀\n",
    "+ 랜덤 포레스트\n",
    "+ 로지스틱 회귀\n",
    "+ XGBoost\n",
    "+ 결정 트리\n",
    "+ LightGBM\n",
    "+ 앙상블 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"선형-회귀-모델\"></a>\n",
    "## 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y = 2x + 5에 근사하는 데이터 100개에 대한 선형 회귀 모델\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0) # 시드 값 고정\n",
    "\n",
    "w0 = 5 # y 절편\n",
    "w1 = 2 # 회귀계수\n",
    "noise = np.random.randn(100, 1) # 노이즈\n",
    "\n",
    "x = 4* np.random.rand(100, 1) # 0~4 사이 실수값 100개 생성 (x값)\n",
    "y = w1*x+w0+noise # y값\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 :  [5.09772262]\n",
      "w1 :  [[1.9808382]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(x,y)\n",
    "\n",
    "print('w0 : ', linear_reg_model.intercept_)\n",
    "print('w1 : ', linear_reg_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 회귀선 그리기\n",
    "y_pred = linear_reg_model.predict(x)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,y_pred, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"로지스틱-회귀-모델\"></a>\n",
    "## 로지스틱 회귀 모델  \n",
    "이진 분류 문제에 사용되는 로지스틱 회귀 모델이다. $x$가 변할 때 $y$가 1이 되는 경향성을 판별하는 모델이다.  \n",
    "* odds  \n",
    "성공확률과 실패 확률의 비율  \n",
    "\n",
    "$$odds = \\tfrac{p(y=1|x)}{1-p(y=1|x)}$$\n",
    "\n",
    "* logit  \n",
    "odds에 log를 취한 함수  \n",
    "\n",
    "$$logit(p) = log(\\tfrac{p}{1-p})$$\n",
    "\n",
    "* sigmoid function  \n",
    "logit 함수의 입력과 출력을 바꾼함수  \n",
    "\n",
    "$$p(X) = \\tfrac{1}{1+e^{-\\beta X}}$$\n",
    "\n",
    "* logistic function  \n",
    "sigmoid 함수 만들어진 예측 모델  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
      "0                  0.2654          0.4601                  0.11890      0  \n",
      "1                  0.1860          0.2750                  0.08902      0  \n",
      "2                  0.2430          0.3613                  0.08758      0  \n",
      "3                  0.2575          0.6638                  0.17300      0  \n",
      "4                  0.1625          0.2364                  0.07678      0  \n",
      "..                    ...             ...                      ...    ...  \n",
      "564                0.2216          0.2060                  0.07115      0  \n",
      "565                0.1628          0.2572                  0.06637      0  \n",
      "566                0.1418          0.2218                  0.07820      0  \n",
      "567                0.2650          0.4087                  0.12400      0  \n",
      "568                0.0000          0.2871                  0.07039      1  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "df[\"label\"] = breast_cancer.target\n",
    "print(df)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step1) train / test 으로 나누기\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최빈 클래스:  1\n",
      "validation 데이터셋 정확도:  0.5877192982456141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 만들기\n",
    "majority_class = train[\"label\"].mode()[0]\n",
    "\n",
    "# 기준모델의 정확도 계산을 위한 데이터 생성\n",
    "y_pred = [majority_class] * len(test)\n",
    "\n",
    "# validation 데이터셋에 대한 정확도 확인\n",
    "print(\"최빈 클래스: \", majority_class)\n",
    "print(\"validation 데이터셋 정확도: \", accuracy_score(test[\"label\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation 데이터셋 정확도 0.9473684210526315\n",
      "validation 데이터셋의 타겟 확률 [[9.94248604e-01 5.75139604e-03]\n",
      " [3.09609046e-02 9.69039095e-01]\n",
      " [1.34983722e-03 9.98650163e-01]\n",
      " [1.42638641e-01 8.57361359e-01]\n",
      " [3.01743109e-05 9.99969826e-01]\n",
      " [6.16150187e-04 9.99383850e-01]\n",
      " [2.71063677e-03 9.97289363e-01]\n",
      " [5.05695474e-04 9.99494305e-01]\n",
      " [7.32929302e-05 9.99926707e-01]\n",
      " [1.31420997e-05 9.99986858e-01]\n",
      " [7.05623977e-01 2.94376023e-01]\n",
      " [1.92600564e-01 8.07399436e-01]\n",
      " [7.28368281e-05 9.99927163e-01]\n",
      " [7.37911102e-01 2.62088898e-01]\n",
      " [3.21821170e-01 6.78178830e-01]\n",
      " [9.90741602e-01 9.25839829e-03]\n",
      " [3.82129316e-04 9.99617871e-01]\n",
      " [9.99999817e-01 1.82887194e-07]\n",
      " [9.95867001e-01 4.13299923e-03]\n",
      " [1.00000000e+00 4.08608413e-10]\n",
      " [9.99904176e-01 9.58240211e-05]\n",
      " [9.65495511e-01 3.45044892e-02]\n",
      " [2.00717945e-03 9.97992821e-01]\n",
      " [3.67701533e-03 9.96322985e-01]\n",
      " [8.67353069e-01 1.32646931e-01]\n",
      " [3.82444937e-03 9.96175551e-01]\n",
      " [1.93714824e-04 9.99806285e-01]\n",
      " [9.26213090e-01 7.37869101e-02]\n",
      " [2.02390512e-03 9.97976095e-01]\n",
      " [9.99999999e-01 5.34141461e-10]\n",
      " [1.17050827e-04 9.99882949e-01]\n",
      " [9.99992130e-01 7.87005516e-06]\n",
      " [2.55388754e-01 7.44611246e-01]\n",
      " [9.99603086e-01 3.96914017e-04]\n",
      " [3.53477706e-06 9.99996465e-01]\n",
      " [9.98710258e-01 1.28974157e-03]\n",
      " [4.88140657e-02 9.51185934e-01]\n",
      " [9.99970068e-01 2.99323156e-05]\n",
      " [6.28901008e-03 9.93710990e-01]\n",
      " [9.99705521e-01 2.94479330e-04]\n",
      " [9.41721805e-01 5.82781953e-02]\n",
      " [4.37681315e-05 9.99956232e-01]\n",
      " [9.97673320e-01 2.32668025e-03]\n",
      " [5.55371739e-05 9.99944463e-01]\n",
      " [8.98642799e-01 1.01357201e-01]\n",
      " [9.99999999e-01 9.54682887e-10]\n",
      " [1.23885961e-06 9.99998761e-01]\n",
      " [4.67269502e-02 9.53273050e-01]\n",
      " [4.06777979e-04 9.99593222e-01]\n",
      " [9.99802382e-01 1.97618205e-04]\n",
      " [9.99998854e-01 1.14648500e-06]\n",
      " [8.75505527e-01 1.24494473e-01]\n",
      " [9.99995408e-01 4.59193247e-06]\n",
      " [1.02664090e-03 9.98973359e-01]\n",
      " [4.94223732e-03 9.95057763e-01]\n",
      " [1.80948488e-04 9.99819052e-01]\n",
      " [2.57451615e-03 9.97425484e-01]\n",
      " [1.34040751e-02 9.86595925e-01]\n",
      " [1.11241739e-02 9.88875826e-01]\n",
      " [1.00000000e+00 1.79126608e-14]\n",
      " [9.95955604e-01 4.04439643e-03]\n",
      " [9.99873209e-01 1.26791407e-04]\n",
      " [2.27679378e-04 9.99772321e-01]\n",
      " [2.77694631e-03 9.97223054e-01]\n",
      " [9.99999863e-01 1.36657778e-07]\n",
      " [6.19860811e-02 9.38013919e-01]\n",
      " [1.00000000e+00 1.98727515e-16]\n",
      " [9.99997722e-01 2.27823650e-06]\n",
      " [9.99999595e-01 4.04545757e-07]\n",
      " [4.38788726e-04 9.99561211e-01]\n",
      " [5.81435761e-01 4.18564239e-01]\n",
      " [9.99997458e-01 2.54189843e-06]\n",
      " [7.05984421e-04 9.99294016e-01]\n",
      " [2.18323331e-01 7.81676669e-01]\n",
      " [9.99992472e-01 7.52798593e-06]\n",
      " [2.11531602e-02 9.78846840e-01]\n",
      " [1.19766057e-05 9.99988023e-01]\n",
      " [1.29771794e-02 9.87022821e-01]\n",
      " [9.86187184e-04 9.99013813e-01]\n",
      " [6.99914482e-05 9.99930009e-01]\n",
      " [9.98041578e-01 1.95842195e-03]\n",
      " [1.00000000e+00 2.17672310e-10]\n",
      " [9.99989424e-01 1.05758181e-05]\n",
      " [9.08421678e-05 9.99909158e-01]\n",
      " [9.54482977e-01 4.55170235e-02]\n",
      " [2.71893507e-04 9.99728106e-01]\n",
      " [1.27877997e-03 9.98721220e-01]\n",
      " [4.61394844e-06 9.99995386e-01]\n",
      " [9.99931751e-01 6.82493883e-05]\n",
      " [1.00000000e+00 2.02530695e-11]\n",
      " [5.40535168e-06 9.99994595e-01]\n",
      " [6.32175130e-01 3.67824870e-01]\n",
      " [7.66520072e-01 2.33479928e-01]\n",
      " [9.99946498e-01 5.35023844e-05]\n",
      " [6.39166047e-04 9.99360834e-01]\n",
      " [5.68157610e-04 9.99431842e-01]\n",
      " [1.00000000e+00 1.48152196e-14]\n",
      " [8.71392635e-02 9.12860737e-01]\n",
      " [1.13161769e-02 9.88683823e-01]\n",
      " [4.09860597e-03 9.95901394e-01]\n",
      " [1.57180650e-05 9.99984282e-01]\n",
      " [2.97106460e-03 9.97028935e-01]\n",
      " [7.14329003e-03 9.92856710e-01]\n",
      " [2.27596100e-01 7.72403900e-01]\n",
      " [9.99999117e-01 8.82992408e-07]\n",
      " [7.52313601e-05 9.99924769e-01]\n",
      " [9.99978964e-01 2.10357560e-05]\n",
      " [3.18988409e-01 6.81011591e-01]\n",
      " [8.60931257e-01 1.39068743e-01]\n",
      " [7.05041963e-01 2.94958037e-01]\n",
      " [1.99345959e-02 9.80065404e-01]\n",
      " [9.94860597e-01 5.13940344e-03]\n",
      " [9.99943658e-01 5.63420371e-05]\n",
      " [1.95348161e-01 8.04651839e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train = train['label']\n",
    "X_train = train.drop(columns='label')\n",
    "y_test = test['label']\n",
    "X_test = test.drop(columns='label')\n",
    "\n",
    "# 모델 생성 및 학습 시키기\n",
    "logistic = LogisticRegression(max_iter=5000) # iter 초과시 증가\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"validation 데이터셋 정확도\", logistic.score(X_test, y_test))\n",
    "print(\"validation 데이터셋의 타겟 확률\", logistic.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"결정-트리\"></a>\n",
    "## 결정 트리\n",
    "\n",
    "1. 데이터를 가장 잘 구분하는 조건을 선정  \n",
    "2. 조건을 기준으로 데이터를 두 범주로 분류  \n",
    "3. 나뉜 각 범주의 데이터를 잘 구분하는 조건을 다시 결정  \n",
    "4. 조건에 따라 각 범주에 속한 데이터를 다시 분할\n",
    "5. 위와 같은 순서로 계속 분할해 최종 결과 값을 도출  \n",
    "\n",
    "> 머신러닝에서 결정트리(decision tree)를 분할하는 방법은 불순도(impurity)를 최소화하는 방향으로 분할한다.  \n",
    "1. 엔트로피 : 0~1, 0에 가까울수록 불순도가 낮아진다.  \n",
    "2. 지니 불순도  : 0~1  \n",
    "\n",
    "* criterion : 불순도 측정 지표 [default : 'gini', 'entropy']\n",
    "* max_depth : 트리 최대 깊이 [default : None]\n",
    "    * min_samples_split과 같은 옵션이 없으면 기본으로 불순도 0까지 분할\n",
    "* min_samples_split : 노드 분할에 필요한 최소 데이터수 [default : 2]\n",
    "    * 정수형, 실수형(비율) 사용가능\n",
    "* min_samples_leaf : 말단 노드가 되기 위한 최소 데이터수 [default : 1]\n",
    "    * 정수형, 실수형(비율) 사용가능\n",
    "* max_features : 분할에 사용할 피쳐수 [default : None]\n",
    "    * 정수형, 실수형(비율) 사용가능\n",
    "    * 'auto', 'sqrt', 'log2' 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 정확도 : 0.939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer['data'],\n",
    "                                breast_cancer['target'],\n",
    "                                stratify=breast_cancer['target'],\n",
    "                                test_size=0.2,\n",
    "                                random_state=0\n",
    "                                )\n",
    "                    \n",
    "decisiontree = DecisionTreeClassifier(random_state=0)\n",
    "decisiontree.fit(X_train, y_train)\n",
    "\n",
    "accuracy = decisiontree.score(X_test, y_test)\n",
    "\n",
    "print(f'결정 트리 정확도 : {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"앙상블-학습\"></a>\n",
    "## 앙상블 학습  \n",
    "\n",
    "다양한 모델에서 나온 결과를 복합적으로 사용하여 성능을 향상하는 기법\n",
    "\n",
    "### 보팅(voting)\n",
    "* 하드 보팅(hard voting)  \n",
    "실행한 모델들에서 나온 결과에서 다수결 투표를 진행\n",
    "* 소프트 보팅(soft voting)  \n",
    "실행한 모델들에서 나온 확률의 평균값으로 진행\n",
    "\n",
    "### 배깅(bagging)  \n",
    "서로 다른 샘플링 데이터를 활용하여 앙상블 모델을 구축  \n",
    "1. 전체 훈련 데이터셋에서 무작위 샘플링한 데이터로 개별 모델을 훈련  \n",
    "2. 훈련된 개별 모델로 결과를 예측  \n",
    "3. 개별 모델의 수만큼 1~2번 작업을 반복  \n",
    "4. 각 모델이 예측한 값들을 보팅하여 최종 예측값을 산출  \n",
    "\n",
    "### 부스팅(Boosting)  \n",
    "가중치를 활용해 분류 성능이 낮은 모델을 높게 만드는 기법이다.  \n",
    "예를 들어, 이전 모델이 잘못 예측한 데이터에 대해 가중치를 적용해 다음 모델이 가중치가 적용된 데이터를 좀 더 고려하면서 학습할 수 있도록 유도한다.  \n",
    "\n",
    "> 부스팅 기법을 활용한 대표적인 모델은 XGBoost와 LightGBM 등이 있다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev_folder\\anaconda3\\envs\\recent\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting 분류기 정확도 0.9649\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#load dataset\n",
    "cancer_dataset = load_breast_cancer()\n",
    "\n",
    "# cancer_dataset 그냥 찍어보니 이상하게 나옴.. dataframe화 해줘야 헸음. \n",
    "cancer_dataset_df = pd.DataFrame(cancer_dataset.data, columns=cancer_dataset.feature_names)\n",
    "cancer_dataset_df.head()\n",
    "\n",
    "\n",
    "# dataset split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset.data, cancer_dataset.target, test_size=0.2, random_state=121)\n",
    "\n",
    "\n",
    "#weak learners: logistic regression, KNN\n",
    "logistic_regression = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "#votinng ensemble with these two weak learners\n",
    "voting_ensemble = VotingClassifier(estimators=[(\"LogisticRegression\", logistic_regression), (\"KNN\", KNN)],\n",
    "                                  voting = 'soft')\n",
    "\n",
    "\n",
    "# voting_ensemble model train/val/test\n",
    "voting_ensemble.fit(X_train, y_train)\n",
    "y_pred = voting_ensemble.predict(X_test)\n",
    "\n",
    "print(\"voting 분류기 정확도 {0:.4f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"랜덤-포레스트\"></a>\n",
    "## 랜덤 포레스트  \n",
    "랜덤 포레스트는 결정 트리에 배깅 방식으로 결합한 모델을 말한다.  \n",
    "파라미터는 decision tree에서 n_estimators(트리의 수)만 추가되었다.\n",
    "\n",
    "* n_estimators : 랜덤 포레스트에 사용될 트리의 수  [default : 100]\n",
    "* criterion : 불순도 측정 지표 [default : 'gini', 'entropy']\n",
    "* max_depth : 트리 최대 깊이 [default : None]\n",
    "    * min_samples_split과 같은 옵션이 없으면 기본으로 불순도 0까지 분할\n",
    "* min_samples_split : 노드 분할에 필요한 최소 데이터수 [default : 2]\n",
    "    * 정수형, 실수형(비율) 사용가능\n",
    "* min_samples_leaf : 말단 노드가 되기 위한 최소 데이터수 [default : 1]\n",
    "    * 정수형, 실수형(비율) 사용가능\n",
    "* max_features : 분할에 사용할 피쳐수 [default : None]\n",
    "    * 정수형, 실수형(비율) 사용가능\n",
    "    * 'auto', 'sqrt', 'log2' 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 정확도 : 0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer['data'],\n",
    "                                breast_cancer['target'],\n",
    "                                stratify=breast_cancer['target'],\n",
    "                                test_size=0.2,\n",
    "                                random_state=0\n",
    "                                )\n",
    "                    \n",
    "decisiontree = RandomForestClassifier(random_state=0)\n",
    "decisiontree.fit(X_train, y_train)\n",
    "\n",
    "accuracy = decisiontree.score(X_test, y_test)\n",
    "\n",
    "print(f'결정 트리 정확도 : {accuracy:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"XGBoost\"></a>\n",
    "## XGBoost\n",
    "성능이 우수한 **트리 기반 부스팅 알고리즘**이다.  \n",
    "\n",
    "파이썬 래퍼 XGBoot를 사용할려면 DMatrix 객체를 활용해 XGBoost 전용 데이터셋을 만들어야 한다.  \n",
    "xgboost.DMatrix() 파라미터는 다음과 같다.   \n",
    "- data : xgboost.DMatrix용 데이터셋  \n",
    "    - 넘파일 배열, 판다스 DataFrame, scpiy.spares, os.PathLike, 문자열 타입을 전달할 수 있다.(o.sPahtLike나 문자열이면 데이터 파일 경로를 의미함)  \n",
    "- label : 타깃값  \n",
    "    - 배열 타입을 전달할 수 있음  \n",
    "\n",
    "for XGBoost() class\n",
    "* booster : 부스팅 알고리즘 [default : 'gbtree', 'dart', 'gblinear']\n",
    "    * gblinear : 선형 모델(성능 하)\n",
    "    * dart : 드롭아웃 적용한 gbtree\n",
    "* objective : 훈련 목적 [default : 'reg:squarederror']\n",
    "    * 회귀에서 'reg:squarederror'\n",
    "    * 확룰성 이진분류에서 'binary:logistic'\n",
    "    * softmax 사용 다중분류에서 'multi:softmax'\n",
    "    * 확률값을 구하는 다중분류에서 'multi:softprob'\n",
    "* eta : 학습률(단계별 가중치) [default : 0.3, 0~1, normally 0.001~0.1]\n",
    "* max_depth : 트리의 최대 깊이 [default : 6, normally 3~10]\n",
    "* subsample : 개별 트리에 사용할 데이터 샘플링 비율 [default : 1, normally 0.6~1]\n",
    "* colsample_bytree : 트리 훈련에 사용하는 피쳐 샘플링 비율 [default : 1, normally 0.6~1]\n",
    "* alpha : L1(lasso) 규제 값 [default : 0]\n",
    "* reg_lambda : L2(Ridge) 규제 값 [default : 1]\n",
    "* gamma(min_split_loss) : leaf node가 분할 하기위한 최소 loss[default : 0, 0~$\\infty$]\n",
    "* min_child_weight : 과적합 방지 값 [default : 1, 0~$\\infty$]\n",
    "* scale_pos_weight : 불균형 데이터 가중치 조정 값 [default : 1]\n",
    "    * 주로 $음성타깃 \\over 양성타깃$ 으로 설정\n",
    "    \n",
    "for train() method\n",
    "* params : dict type 하이퍼 파라미터 목록\n",
    "* dtrain : 훈련 데이터셋\n",
    "* num_boost_round : 부스팅 반복 횟수 [default : 10]\n",
    "    * 성능, 과적합, 시간의 상관관계가 있음\n",
    "* evals : 검증용 데이터 셋 [default : []]\n",
    "* feval : 검증용 평가지표 evals사용시 활용 [default : None]\n",
    "* maximize : feval이 높은게 좋은가? [True, False]\n",
    "* early_stopping_rounds : 조기종료 옵션 [default : None, int]\n",
    "    * eta가 크면 줄이고 작으면 키움\n",
    "    * evals가 필요함\n",
    "    * 옵션의 숫자만큼 반복하고 다음번으로 반복한 결과와 비교해 성능이 감소하면 종료\n",
    "* verbose_eval : 성능 점수 로그 설정 [default : True, False, int]\n",
    "    * 설정된 횟수만큼 반복후 성능지표를 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"LightGBM\"></a>\n",
    "## LightGBM\n",
    "\n",
    "for LightGBM() class\n",
    "* boosting_type : 부스팅 알고리즘 [default : 'gbdt', 'dart', 'goss','rf]\n",
    "    * g\n",
    "* objective : 훈련 목적 [default : 'regression']\n",
    "    * 회귀에서 'regression'\n",
    "    * 이진분류에서 'binary'\n",
    "    * 다중분류에서 'multiclass'\n",
    "* learning_rate(eta) : 학습률(단계별 가중치) [default : ]\n",
    "* num_leaves : leaf node 갯수 커지면 과적합 위험 [default : 31]\n",
    "* max_depth : 트리의 최대 깊이 [default : -1]\n",
    "* bagging_fraction(subsample) : 개별 트리에 사용할 데이터 샘플링 비율 [default : not 0]\n",
    "    * g\n",
    "* feature_fraction(colsample_bytree) : 트리 훈련에 사용하는 피쳐 샘플링 비율 [default : ]\n",
    "    * g\n",
    "* lambda_l1(reg_alpha) : L1(lasso) 규제 값 [default : 0]\n",
    "* lambda_l2(reg_lambda) : L2(Ridge) 규제 값 [default : 0]\n",
    "* min_child_samples : leaf node가 되기위한 최소 데이터 수 [default : 20]\n",
    "* min_child_weight : 과적합 방지 값 [default : $1e^{-3}$, 0~$\\infty$]\n",
    "* bagging_freq : 배깅 수행 빈도 [default : 0]\n",
    "    * 몇번의 iter 마다 배깅을 할지 결정\n",
    "* force_row_wise : 메모리 효율 증가 [default : False, True]\n",
    "\n",
    "for train() method\n",
    "* params : dict type 하이퍼 파라미터 목록\n",
    "* train_set : 훈련 데이터셋\n",
    "* num_boost_round : 부스팅 반복 횟수 [default : 10]\n",
    "    * 성능, 과적합, 시간의 상관관계가 있음\n",
    "* valid_sets : 검증용 데이터 셋 [default : None]\n",
    "* feval : 검증용 평가지표 evals사용시 활용 [default : None]\n",
    "* categorical_feature : 범주형 데이터 지정옵션\n",
    "* early_stopping_rounds : 조기종료 옵션 [default : None, int]\n",
    "    * eta가 크면 줄이고 작으면 키움\n",
    "    * evals가 필요함\n",
    "    * 옵션의 숫자만큼 반복하고 다음번으로 반복한 결과와 비교해 성능이 감소하면 종료\n",
    "* verbose_eval : 성능 점수 로그 설정 [default : True, False, int]\n",
    "    * 설정된 횟수만큼 반복후 성능지표를 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoot와 LightGBM의 강점  \n",
    "\n",
    "1. 피처 스케일링이 따로 필요없다. 데이터의 절대적인 크기보다는 대소 관계에 영향을 받기 때문이다.  \n",
    "2. 레이블 인코딩을 적용해도 된다. 레이블 인코딩은 단점이 있다고 했지만, 트리 기반 모델의 특성상 분기르 ㄹ거릅하면서 레이블 인코딩된 피처에서도 정보를 잘 추출할 수 있기 때문이다.  \n",
    "3. 결측값을 알아서 처리해준다. (그럼에도 더 명확하게 하려면 결측값을 별도로 처리하는 습관을 들이는게 바람직하다.)  \n",
    "단, 선형모델은 피처 스케일링, 결측값 처리, 원-핫 인코딩을 해줘야 일반적으로 성능이 좋아진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런 래퍼 모듈 vs. 파이썬 래퍼 모듈  \n",
    "사이킷런은 XGBoost와 LightGBM을 비롯해 여러 모델을 지원한다. 다음 표에 사이킷런 패러 모듈과 파이썬 래퍼 모듈 사용범의 차이를 정리했다. \n",
    "\n",
    "|구분|사이킷런 래퍼 모델 | 파이썬 래퍼 모듈|\n",
    "|--|--|--|\n",
    "|모델 생성|모델이 워낙 많다보니 클래스 활용,<br> 예) LogisticRegression(),  XGBRegressor(),  LGBMClassifier() | 별도로 모델을 생성하지 않고, 임포트한 xgboost 혹은 lightgmb을 그대로 사용 <br> 예) import xgboost <br> import lightgbm |\n",
    "|데이터셋| 별도로 데이터셋을 생성하지 않고 원본 데이터(배열, DataFrame 등의 타입)를 그대로 사용 | 별로 데이터셋을 생성 <br> XGBoot는 DMatrixi 객체 활용, LightGBM은 Dataset 객체 활용 <br> 예) xgboost.DMatrix() <bar> lightgbm.Dataset() |\n",
    "|모델 훈련| 생성한 모델 객체의 fit() 메서드를 호출 | 임포트한 xgboost 혹은 lightgbm 모듈을 바로 사용해서 train() 메서드 호출|\n",
    "|예측 | 생성한 모델 객체의 predict() 혹은 predict_proba() 메서드로 예측 | predict() 메서드로 예측|\n",
    "|하이퍼 파라미터 입력 방식| 모델 하이퍼 파라미터는 모델 생성 시 입력하고, 훈련 하이퍼 파라미터는 fit() 메서드에 입력| 모두 train() 메서드에 입력 <br> 모델 하이퍼 파라미터는 train()의 params 파라미터에 일괄 입력|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"하이퍼-파라미터-최적화\"></a>\n",
    "# 하이퍼 파라미터 최적화  \n",
    "최적의 파라미터를 찾아가는 방법  \n",
    "하이퍼 파라미터를 요리에 비유하면서 설명했다. 레시피가 있지만, 매운맛을 좋아하는 사람은 고추장을 더 넣거나 싱겁게 먹는 사람은 소금을 덜 넣거나 한다. 이와 같이 모델에서도 분석자가 입력하는 데이터의 의미를 파악하면서 하이퍼 파라미터의 최적화를 수행한다.  \n",
    "대표적으로 그리드서치, 랜덤서치, 베이지안 최적화 이렇게 볼 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"그리드서치\"></a>\n",
    "## 그리드서치  \n",
    "모든 경우의 수를 탐색하는 방식이다. 그래서 많은 시간이 필요한게 단점이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"랜덤서치\"></a>\n",
    "## 랜덤서치(random search)  \n",
    "하이퍼 파라미터를 무작위로 추출하여 최적의 파라미터를 찾아가는 방법이다. 무작위라는 한계 때문에 사용빈도가 떨어진다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"베이지안-최적화\"></a>\n",
    "## 베이지안 최적화(bayesian optimization)  \n",
    "`bayes_opt`라는 패키지로 베이지안 최적화를 구현  \n",
    "수행 절차는 다음과 같다.  \n",
    "1. 하이퍼 파라미터 탐색 범위 설정  \n",
    "    ```python\n",
    "    # 하이퍼 파라미터 범위(딕셔너리 형태)\n",
    "    param_bounds = {'x': (-1, 5),\n",
    "                    'y': (0,  4)}\n",
    "    ```\n",
    "2. 평가지표 계산 함수(성능 평가 함수) 정의  \n",
    "    ```python\n",
    "    # 예시\n",
    "    def eval_function(x,y):\n",
    "        return -x ** 2 - ( - 2) ** 2 + 10\n",
    "    ```\n",
    "3. Bayesian Optimization 객체 생성 : bayes_opt 패키지의 `BayesianOptimization` 객체를 생성한다. 객체 생성 시 **평가지표 계산 함수**와 **하이퍼 파라미터 탐색 범위**를 전달 받는다.  \n",
    "    ```python\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    # 베이지안 최적화 객체 생성\n",
    "    optimizer = BayesianOptimization(f=eval_function,\n",
    "                                       pbounds=param_bounds,\n",
    "                                       random_state=0)\n",
    "    ```\n",
    "4. 베이지안 최적화 수행 : 3번에서 생성한 BayesinOptimization 객체의 maximize() 메서드를 호출한다. 하이퍼 파라미터 범위 내에서 평가 지표를 계산한 평가 지표가 가장 좋은 하이퍼 파라미터를 최적이라고 판단한다.  \n",
    "    * init_points : 랜덤 탐색의 스텝 횟수\n",
    "    * n_iter : 베이지안 실행 횟수  \n",
    "    ```python\n",
    "        optimizer.maximize(init_points=2, n_iter=10)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_bounds = {'max_depth': (4, 8),\n",
    "'subsample': (0.6, 0.9),\n",
    "'colsample_bytree': (0.7, 1.0),\n",
    "'min_child_weight': (5, 7),\n",
    "'gamma': (8, 11),\n",
    "'reg_alpha': (7, 9),\n",
    "'reg_lambda': (1.1, 1.5)}\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def eval_function(max_depth, subsample, colsample_bytree, min_child_weight, gamma, reg_alpha, reg_lambda):\n",
    "  param_bounds = {'max_depth': max_depth,\n",
    "                  'subsample': subsample,\n",
    "                  'colsample_bytree': colsample_bytree,\n",
    "                  'min_child_weight': min_child_weight,\n",
    "                  'gamma': gamma,\n",
    "                  'reg_alpha': reg_alpha,\n",
    "                  'reg_lambda': reg_lambda}\n",
    "  xgb_model = xgb.train(params=params, dtrain=train, num_boost_round=2000, evals=[(valid, 'valid')], maximize=True, early_stopping_round=200)\n",
    "  best_iter = xgb_model.best_iteration\n",
    "  preds = xgb_model.predict(valid, iteration_range=(0, best_iter))\n",
    "  score = roc_auc_score(y_valid, preds)\n",
    "\n",
    "  return score\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds)\n",
    "\n",
    "optimizer.maximize(init_points=3, n_iter=10)\n",
    "\n",
    "max_params = optimzier.max['params']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b363c58d1093e891c4eaaf9273db69d0f7db3f9909d89c6197aa3afcc07f476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
